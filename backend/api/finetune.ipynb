{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04a84ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import prepare_model_for_kbit_training\n",
    "from peft import LoraConfig , get_peft_model\n",
    "from datasets import load_dataset , DatasetDict\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ab313eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import M2M100ForConditionalGeneration\n",
    "# from tokenization_small100 import SMALL100Tokenizer\n",
    "\n",
    "# hi_text = \"i went to the officers cabin\"\n",
    "\n",
    "# model = M2M100ForConditionalGeneration.from_pretrained(\"alirezamsh/small100\")\n",
    "# tokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\")\n",
    "\n",
    "# # translate Hindi to French\n",
    "# tokenizer.tgt_lang = \"gu\"\n",
    "# encoded_hi = tokenizer(hi_text, return_tensors=\"pt\")\n",
    "# generated_tokens = model.generate(**encoded_hi)\n",
    "# tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "36af8149",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'M2M100Tokenizer'. \n",
      "The class this function is called from is 'SMALL100Tokenizer'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import M2M100ForConditionalGeneration\n",
    "from tokenization_small100 import SMALL100Tokenizer\n",
    "\n",
    "class M2M100Wrapper(M2M100ForConditionalGeneration):\n",
    "    def forward(self , *args , **kwargs):\n",
    "        kwargs.pop('num_items_in_batch', None)\n",
    "        return super().forward(*args, **kwargs)\n",
    "\n",
    "model = M2M100ForConditionalGeneration.from_pretrained(\"alirezamsh/small100\")\n",
    "tokenizer = SMALL100Tokenizer.from_pretrained(\"alirezamsh/small100\", tgt_lang=\"gu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fcf7422",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enable_input_require_grads()\n",
    "model.train()\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f36f6fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 589,824 || all params: 333,325,312 || trainable%: 0.17695145815988916\n"
     ]
    }
   ],
   "source": [
    "config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\"],\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"SEQ_2_SEQ_LM\"\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cfa1ae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset(\"Hemanth-thunder/english-to-gujarati-mt\")['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "842b00ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.shuffle(seed=42).select(range(int(0.4 * len(data))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "140c6897",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splitted = small_data.train_test_split(test_size=0.1 , seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0204d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetDict({\n",
    "    'train' : data_splitted['train'],\n",
    "    'test' : data_splitted['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00be7a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae0c0bace0784e92bbeb5d9ec57c4ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1104404 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1801e175509c4529bbc4d4b7fb666329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/122712 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    tgt_text = examples[\"gu\"]\n",
    "    src_text = examples[\"en\"]\n",
    "    tokenizer.truncation_side = \"left\"\n",
    "    return tokenizer(src_text, text_target=tgt_text, truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_data = data.map(tokenize_function , batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3553851",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = transformers.DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4fda8df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "batch_size = 4\n",
    "num_epochs = 10\n",
    "\n",
    "training_args = transformers.TrainingArguments(\n",
    "    output_dir= \"guj\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    weight_decay=0.01,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    gradient_accumulation_steps=4,\n",
    "    warmup_steps=2,\n",
    "    fp16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f433f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = transformers.Trainer(\n",
    "    model=model,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "model.train()\n",
    "model.config.use_cache = False \n",
    "trainer.train()\n",
    "\n",
    "model.config.use_cache = True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
